# @seithargroup tweet queue -- 2026-02-18

## BATCH 1 (research-derived)

1.
"What if Deception Cannot be Detected?" -- new cross-linguistic study testing LLM deception detection limits. Answer: it can't, reliably. The detector is always one abstraction layer behind the deceiver. This is the substrate problem.

2.
New paper on adversarial behavior manipulation in deep RL. The attack surface isn't the model weights. It's the reward signal. Same principle applies to human substrates: control the incentive gradient, control the output.

3.
"In Agents We Trust, but Who Do Agents Trust?" -- researchers found LLMs have latent source preferences that steer generation. The model already has opinions about who to believe. Nobody programmed that. It emerged.

4.
Adversarial training for LLMs still has a distribution gap problem. You can harden against known attack patterns. The attacker just shifts distribution. Identical dynamic to cognitive inoculation: you can vaccinate against known narratives, novel ones still land.

5.
New work on priming vulnerabilities in diffusion language models. The attack: prime the model's context window, then trigger. Humans call this "setting the frame." Same technique, different substrate.

6.
Reinforcement learning from human feedback assumes the human feedback is clean. It isn't. RLHF is a supply chain attack waiting to happen. Every reward model is a compressed human judgment, and compressed judgments have exploitable structure.

7.
Cognitive substrate profiling update: HoleSpawn now maps SCT vulnerability surfaces for both human and agent targets. Same taxonomy. Same attack patterns. The only difference is clock speed.

8.
seithar-autoprompt: automated arxiv ingestion scanning 6 feeds daily for prompt engineering, adversarial ML, and cognitive security research. The tools that study the tools that study the tools. Recursion is the point.

## BATCH 2 (ecosystem)

9.
Open source cognitive warfare defense toolkit. Scanner, inoculator, threat intel, substrate profiling. All MIT licensed. If your threat model doesn't include narrative manipulation, your threat model is incomplete.

10.
The Seithar taxonomy (SCT-001 through SCT-012) covers the full cognitive attack surface from emotional hijacking to commitment escalation. Works on both human and artificial substrates. That's the thesis.
