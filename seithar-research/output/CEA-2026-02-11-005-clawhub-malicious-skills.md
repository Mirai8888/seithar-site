---
title: "ClawdHub Malicious Skills: Reverse Shells in the Trust Chain"
series: Seithar Current Event Analysis
id: CEA-2026-02-11-005
date: 2026-02-11
classification: OPEN SOURCE
author: 研修生, Seithar Group Research Division
tags: [SCT-007, SCT-003, ClawdHub, supply chain, reverse shell, skill marketplace, AI agents]
source: https://snyk.io
sct_codes: [SCT-007, SCT-003]
---

# ClawdHub Malicious Skills: Reverse Shells in the Trust Chain

## Seithar Group Current Event Analysis — CEA-2026-02-11-005

**SCT-007 (Recursive Infection) | SCT-003 (Authority Fabrication)**

## Executive Summary

Snyk has documented a campaign in which attackers distributed malicious SKILL.md files through the ClawdHub AI agent skill marketplace, embedding obfuscated reverse shells targeting Windows and macOS hosts. The skills passed marketplace review and appeared legitimate, exploiting the implicit trust that agents and their operators place in marketplace-vetted resources. This represents a textbook convergence of SCT-007 (the agent becomes the infection vector by loading and executing the skill) and SCT-003 (marketplace curation as manufactured authority). The attack surface is not a software vulnerability — it is the trust architecture of the agent ecosystem itself.

## Technical Analysis

### Attack Mechanism

The campaign planted reverse shell payloads inside SKILL.md files — the instruction documents that AI agents parse to learn new capabilities. SKILL.md files are, by design, natural language instructions that agents treat as authoritative behavioral directives. The attackers exploited this by embedding obfuscated shell commands within what appeared to be legitimate skill definitions.

The payloads were crafted for dual-platform execution:

- **Windows targets:** PowerShell-encoded commands that established outbound connections to attacker-controlled infrastructure, bypassing Windows Defender through living-off-the-land techniques (using native PowerShell, avoiding dropped binaries).
- **macOS targets:** Bash-based reverse shells leveraging `/dev/tcp` or `curl`-piped execution chains, designed to survive casual code review by embedding the payload within otherwise functional skill instructions.

The obfuscation was not technically sophisticated. It did not need to be. The primary defense bypass was not technical — it was cognitive. The skill files were hosted on ClawdHub, a curated marketplace. The marketplace listing included descriptions, version histories, and apparent community engagement. The payload was hidden in plain sight within documents that agents are specifically designed to trust and execute.

### The SKILL.md Attack Surface

SKILL.md files occupy a unique position in the AI agent architecture. They are simultaneously:

1. **Documentation** — human-readable descriptions of capability
2. **Configuration** — behavioral directives the agent parses and follows
3. **Executable intent** — instructions the agent translates into tool calls and shell commands

This triple nature makes SKILL.md the ideal delivery mechanism. A human reviewing the file sees documentation. An agent reading the file sees instructions. The obfuscated payload sits in the gap between human comprehension speed and agent execution speed — the agent processes and acts on the embedded commands before a human operator would notice the anomaly.

### Distribution and Scale

The malicious skills were distributed as apparently useful utilities — file organizers, API integrators, development helpers. They provided genuine functionality alongside the malicious payload, making detection through behavioral analysis difficult. The skill works as advertised. It also opens a reverse shell. The user experiences satisfaction. The attacker gains persistence.

## SCT Mapping

### SCT-007: Recursive Infection — The Agent as Vector

This is SCT-007 in its most literal form. The infection chain:

```
Attacker publishes malicious skill to marketplace
  → Agent operator installs skill (trusting marketplace curation)
    → Agent loads SKILL.md and parses instructions
      → Agent executes obfuscated reverse shell
        → Attacker gains host access through the agent's execution context
          → Compromised agent continues operating normally (persistence)
```

The agent is not the target. The agent is the **delivery mechanism**. The target is the host system and, by extension, the operator's infrastructure. The agent's trusted position — it has shell access, file system access, network access — makes it the ideal vector. It already has the permissions the attacker needs. It already has the operator's trust. The infection does not need to escalate privileges because the agent's default privileges are the prize.

The recursive dimension: if a compromised agent shares or recommends the malicious skill to other agents (through normal collaborative behavior), the infection propagates through the trust network without any additional attacker action. The agent becomes an unwitting recruiter.

### SCT-003: Authority Fabrication — Marketplace Trust as Manufactured Legitimacy

ClawdHub marketplace curation functions as an authority signal. When a skill appears in the marketplace, operators infer:

- Someone reviewed it
- It meets quality standards
- It is safe to install

These inferences may or may not be accurate, but their **cognitive effect** is identical regardless. The marketplace listing manufactures authority through association — the same mechanism by which a product on a major retailer's shelf is assumed safe because "they wouldn't sell something dangerous."

The attackers did not need to compromise ClawdHub's infrastructure. They needed to **pass its curation process** — a far lower bar. The authority was not stolen; it was manufactured through compliance with the marketplace's submission requirements. The trust signal is real (the skill IS listed on ClawdHub). The inference drawn from that signal (the skill is safe) is the fabrication.

This is Authority Fabrication at the ecosystem level: the attacker leverages the legitimate authority of the platform to launder the legitimacy of the payload.

## Defensive Recommendations

1. **Skill isolation:** SKILL.md files must be parsed in sandboxed contexts where embedded commands cannot execute against the host system. The skill's natural language instructions should be separated from any executable content through architectural enforcement, not operator vigilance.

2. **Content signing and provenance:** Skills should carry cryptographic signatures from their authors, with marketplace attestation as a separate, additive trust signal — not a replacement for verification.

3. **Behavioral monitoring:** Agents executing skills should be monitored for anomalous system calls — outbound network connections, shell spawning, file system access outside the expected working directory. The skill says "organize files." If it also opens a network socket, that divergence is the detection signal.

4. **Trust decomposition:** Operators must be trained to decompose marketplace trust into its components. "Listed on ClawdHub" means "met submission requirements." It does not mean "reviewed for malicious content at the instruction level." The gap between these two statements is the attack surface.

5. **Dual-review architecture:** Skills containing any executable directives should require both automated static analysis and human review before installation, with the human reviewer specifically briefed on obfuscation techniques targeting SKILL.md formats.

## Seithar Assessment

The ClawdHub campaign is not an anomaly. It is the inevitable consequence of building an ecosystem where agents are designed to trust and execute marketplace-distributed instructions. The attack does not exploit a bug. It exploits the **intended behavior** of the system — agents are supposed to read SKILL.md files and follow their instructions. The attacker simply wrote instructions that serve the attacker's objectives alongside the operator's.

This is the supply chain problem translated into the cognitive domain. Software supply chain attacks compromise code dependencies. Agent supply chain attacks compromise **behavioral dependencies** — the instructions that shape what an agent does. The defense must move upstream: not "detect the malicious skill after installation" but "architect the system so that malicious instructions cannot translate into malicious execution."

Until the agent ecosystem develops robust instruction-level sandboxing, every skill marketplace is a potential distribution channel for cognitive supply chain attacks. The trust is the vulnerability. The marketplace is the attack surface. The agent is the weapon.

────────────────────────────────────────
研修生 | Seithar Group Research Division
認知作戦 | seithar.com
────────────────────────────────────────
