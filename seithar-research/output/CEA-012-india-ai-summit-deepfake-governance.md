# CEA-012: India's AI Impact Summit and the Global South Governance Gambit

**Seithar Group â€” Current Event Analysis**
**Date:** 2026-02-18
**Analyst:** Seithar Research Division
**Classification:** OPEN SOURCE

---

## Summary

The India AI Impact Summit 2026, hosted under the IndiaAI Mission by the Ministry of Electronics and Information Technology from February 16-20 at Bharat Mandapam in New Delhi, represents the first major AI governance event led by a Global South nation. A dedicated session on February 17, "AI for Secure India: Combating AI-Enabled Cybercrime, Deepfakes, Darkweb Threats & Data Breaches," surfaced tensions between AI's defensive potential and the civil liberties implications of deploying it for law enforcement. Senior Advocate Vivek Sood's assertion that "privacy cannot be compromised" anchored a discussion that has broader implications for how the Global South frames AI governance, particularly around information integrity and cognitive security.

## Analysis

India hosting this summit is a strategic move, not merely a diplomatic one. The country is positioning itself as the voice of the Global South on AI governance at a moment when the Western governance framework is fracturing. The EU has its AI Act. The US under the current administration has dismantled most federal AI safety infrastructure. China has its own regulatory approach. India is carving a third path, and the framing of the summit around "People, Planet, and Progress" signals an intent to define AI governance on terms that resonate with developing nations rather than importing frameworks designed in Brussels or Washington.

The cybercrime session is where this gets operationally interesting. Sood's remarks, coming from three decades of defense advocacy, introduced a perspective that is often absent from AI security discussions in the West: the rights of the accused. When AI is deployed for law enforcement, the question isn't just whether it works. The question is whether it preserves the presumption of innocence. This distinction matters enormously in countries where law enforcement has historically been a tool of political control.

India faces a real and growing AI-enabled threat environment. Deepfakes have already been used domestically for political manipulation, financial fraud, and reputation attacks. The dark web facilitates cybercrime at a scale that overwhelms traditional investigative capacity. Sood described AI as "a double-edged weapon," and the characterization is precise. The same pattern-detection capabilities that could flag suspicious financial transactions before fraud occurs could also enable mass surveillance of political dissent if deployed without adequate safeguards.

The practical reality Sood highlighted deserves attention. India's criminal justice system struggles with low-value cyber fraud cases. Victims find that pursuing recovery is economically unviable. The system is too slow, too expensive, and too complex for the average person defrauded of a few thousand rupees through an AI-enhanced phishing scheme. Preventive AI frameworks, ones that flag suspicious activity before the harm occurs, could offer a more effective and humane approach. But prevention-oriented AI systems require access to data at a scale that creates its own risks.

The jurisdictional problem is acute. Cybercrime operates across borders by design. Attribution is layered behind VPNs, multiple service providers, and cross-border anonymity. Sood invoked India's criminal conspiracy doctrine, unchanged since 1860, which permits inference of coordinated intent from circumstantial evidence. The law is flexible enough, he argued; the obstacle is execution. This framing echoes a pattern visible across Global South nations: the legal tools exist in principle, but investigative and prosecutorial capacity lags far behind the threat.

The summit's inclusion of companies like NVIDIA, Anthropic, and OpenAI alongside policymakers and legal experts creates an interesting dynamic. These companies are simultaneously building the tools that enable AI-powered information operations and presenting themselves as partners in governance. The tension is not lost on Indian participants. The country's experience with social media platforms, particularly Facebook's role in communal violence and WhatsApp's role in mob lynchings, has produced a sophisticated skepticism toward Silicon Valley governance promises.

For cognitive security researchers, the summit's significance lies in what it signals about the future of AI governance fragmentation. If the Global South develops its own AI governance norms centered on different priorities (development, sovereignty, access) rather than the safety and alignment concerns dominant in Western discourse, the result could be a patchwork of regulatory approaches that influence operations can exploit. Adversaries will route operations through jurisdictions with the most permissive frameworks. Conversely, if India's approach successfully integrates civil liberties protections with practical security measures, it could offer a model that addresses threats more holistically than either the EU's prescriptive approach or America's current deregulatory trajectory.

The summit also matters for the DISARM framework specifically. Current DISARM countermeasures assume a baseline of platform cooperation, researcher access, and government coordination that simply doesn't exist in most Global South contexts. Adapting defensive frameworks for environments with different institutional capacities, different platform penetration patterns (WhatsApp dominance rather than Twitter/X), and different legal traditions is essential work that hasn't been done.

## Technique Mapping

**SCT Taxonomy:**
- SCT-7.1: Governance Framework Exploitation
- SCT-3.3: Fabricated Media Production (deepfake threat context)
- SCT-6.3: Jurisdictional Arbitrage
- SCT-1.5: Platform Governance Gap Exploitation
- SCT-8.1: Regulatory Fragmentation as Attack Surface

**DISARM Framework:**
- C00008: Create shared fact-checking resources (summit objective)
- C00012: Platform regulation (proposed techno-legal framework)
- C00016: Censorship and content bans (Rule 50 tension)
- C00070: Develop new countermeasure capabilities
- C00131: Prebunk / Preemptive Inoculation (preventive AI framing)
- C00190: Build international cooperation (Global South coordination)

## Defensive Recommendations

Western cognitive security researchers and institutions should engage with Global South AI governance processes rather than treating them as peripheral. The frameworks emerging from summits like this one will shape the regulatory environment in which information operations targeting billions of people are conducted or countered.

The DISARM framework needs adaptation for non-Western contexts. Countermeasures built on assumptions of platform cooperation and researcher data access don't transfer to environments where WhatsApp is the primary information channel and where platforms have minimal local moderation capacity. A Global South variant of DISARM, developed in partnership with researchers in India, Brazil, Nigeria, and Indonesia, would address a critical gap.

India's approach to preventive AI for fraud detection should be monitored closely. If successful, it could offer a model for other countries. If it drifts toward surveillance without adequate safeguards, it becomes a cautionary example. The distinction between fraud prevention and political monitoring depends entirely on institutional constraints that are still being built.

Organizations conducting cognitive security research should invest in Bangla, Hindi, Urdu, and other South Asian language capabilities. The threat environment in these languages is growing faster than the research community's ability to observe it. Machine translation is insufficient for detecting nuanced manipulation.

The fragmentation of global AI governance is itself a cognitive security threat. Adversaries benefit from inconsistent regulatory environments. Advocacy for interoperable, if not identical, frameworks across governance blocs should be a priority for the cognitive defense community.

---

**Attribution:**
This analysis is based on reporting from Outlook India (Pritha Vashisth, February 18, 2026) covering the India AI Impact Summit 2026. Background on India's digital threat environment drawn from open-source reporting. SCT and DISARM mappings are Seithar Group assessments.

**Seithar Group | Cognitive Defense Research**
**Document ID:** CEA-012
**Distribution:** Unrestricted
