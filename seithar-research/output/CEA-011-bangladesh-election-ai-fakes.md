# CEA-011: AI-Generated Disinformation in Bangladesh's Post-Revolution Election

**Seithar Group â€” Current Event Analysis**
**Date:** 2026-02-18
**Analyst:** Seithar Research Division
**Classification:** OPEN SOURCE

---

## Summary

Bangladesh held its first nationwide election on February 12, 2026, since student-led protests ousted Prime Minister Sheikh Hasina in August 2024. BBC Verify documented the spread of AI-generated videos, deepfakes, and false claims across social media platforms during the voting period. The election took place in a volatile information environment shaped by the trauma of recent political upheaval, limited institutional trust, and high social media penetration among a young, politically activated population. The deployment of AI-generated disinformation in this context illustrates how generative AI tools are being weaponized in fragile democratic transitions where institutional safeguards are weakest.

## Analysis

Context shapes everything here. Bangladesh's 2024 revolution was driven by students. It was fast, digitally coordinated, and it toppled a government that had held power for 15 years. The interim administration that followed inherited a country with deep political fractures, a decimated institutional apparatus, and a population that had just demonstrated it could be mobilized through social media at extraordinary speed. That same mobilization infrastructure became the attack surface for information operations during the February 2026 vote.

BBC Verify's Shruti Menon, reporting from Dhaka, tracked multiple categories of manipulated content circulating during the election. The specifics reported include AI-generated videos and fabricated claims designed to influence voter behavior. While the BBC's live coverage focused on documenting the phenomenon rather than attributing it to specific actors, the pattern is consistent with both domestic political manipulation and potential foreign interference.

Bangladesh sits in a complex geopolitical information environment. India, China, and Pakistan all have strategic interests in the country's political trajectory. The Hasina government maintained close ties with India; its removal opened space for competing influences. Any of these actors, or domestic political factions, could have incentives to deploy information operations during a transitional election.

The demographic profile of the electorate matters for understanding vulnerability. Bangladesh has one of the highest rates of social media adoption in South Asia. Facebook is effectively the internet for millions of Bangladeshis. WhatsApp and Telegram serve as primary information channels, particularly for political content. These platforms combine high reach with limited content moderation capacity for Bangla-language content. Meta has historically underinvested in non-English content moderation, and the 2024 revolution further strained whatever mechanisms existed.

AI-generated content in this environment doesn't need to be sophisticated. It needs to be fast. In a country where trust in traditional media was already damaged by the Hasina era's press restrictions, social media content carries disproportionate weight. A convincing deepfake video of a political figure making inflammatory statements can travel through WhatsApp groups faster than any fact-checking organization can respond. The asymmetry between creation speed and verification speed is the core vulnerability.

The election itself proceeded, and results came in. But the information environment surrounding it was poisoned in ways that are difficult to quantify after the fact. This is the fundamental measurement problem with election-related disinformation. You can document the existence of fake content. You can sometimes estimate its reach. What you can't measure is the cumulative effect on voter confidence, turnout decisions, and perceptions of legitimacy. When AI-generated content circulates during a first post-revolution election, it doesn't just potentially influence individual vote choices. It corrodes trust in the democratic process itself, at precisely the moment when that trust is most fragile and most needed.

The Bangladesh case also highlights a gap in the international election observation framework. Traditional election monitors assess polling station integrity, ballot counting procedures, and legal compliance. The information environment in which voters form their decisions falls largely outside this mandate. Organizations like the EU Election Observation Mission and the Carter Center have begun incorporating media monitoring, but the capacity to detect and assess AI-generated content in local languages during a live election remains severely limited.

There is a resource asymmetry that compounds the problem. Generating AI deepfakes and fabricated news content for a Bangladeshi audience is cheap. Detecting, attributing, and countering that content in Bangla, in real time, during a politically charged election, is expensive and requires specialized expertise that barely exists. The defenders are outmatched not by sophistication but by economics.

This won't be the last transitional election targeted by AI-generated disinformation. Every country emerging from political crisis into its first democratic vote faces the same vulnerability profile: low institutional trust, high social media dependence, limited platform moderation capacity for local languages, and motivated actors seeking to influence outcomes. The list of upcoming elections meeting these criteria is long.

## Technique Mapping

**SCT Taxonomy:**
- SCT-3.3: Fabricated Media Production (deepfake video)
- SCT-3.2: AI-Assisted Content Generation
- SCT-2.1: Event-Triggered Narrative Exploitation
- SCT-4.4: Encrypted Channel Amplification (WhatsApp, Telegram)
- SCT-6.2: Electoral Process Targeting
- SCT-1.4: Platform Moderation Gap Exploitation

**DISARM Framework:**
- T0086: Develop Fake Images/Videos
- T0111: Develop AI-Generated Content
- T0115: Post Content
- T0049: Flood Information Space
- T0128: Amplify Existing Narratives
- T0100: Co-opt Trusted Sources (fabricated attributions)
- T0126: Leverage Platform Algorithm

## Defensive Recommendations

International election observation missions should integrate real-time information environment monitoring as a core function, not an add-on. This requires partnerships with local digital rights organizations and pre-positioned monitoring infrastructure.

Platform companies must invest in non-English content moderation proportionate to user populations. Bangladesh has over 50 million Facebook users. The moderation capacity for Bangla-language content should reflect that scale. AI-based detection tools for Bangla deepfakes and synthetic text need development and deployment before the next electoral cycle.

Local fact-checking organizations need sustainable funding models. The current reliance on platform grants creates dependency and potential conflicts of interest. Independent funding from press freedom foundations and development agencies would strengthen resilience.

Governments conducting transitional elections should establish election information integrity units with the authority and technical capacity to coordinate rapid response to viral disinformation. These units must be politically independent and transparent in their operations to avoid becoming tools of the incumbent.

Voter education campaigns in high-social-media-penetration countries should specifically address AI-generated content. Teaching voters that video and audio can now be fabricated convincingly is a precondition for informed democratic participation in the current media environment.

---

**Attribution:**
This analysis is based on BBC Verify live coverage (February 12, 2026), including field reporting by Shruti Menon from Dhaka. Background context on Bangladesh's political transition drawn from open-source reporting. SCT and DISARM mappings are Seithar Group assessments.

**Seithar Group | Cognitive Defense Research**
**Document ID:** CEA-011
**Distribution:** Unrestricted
